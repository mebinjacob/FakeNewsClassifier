{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake-news.zip\t\t\t   glove.6B.100d.txt  glove.6B.zip\r\n",
      "fake.csv\t\t\t   glove.6B.200d.txt  train_stances.csv\r\n",
      "fake_or_real_news.csv\t\t   glove.6B.300d.txt\r\n",
      "fake_real_news_dataset-master.zip  glove.6B.50d.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls /data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/data/fake.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>ord_in_thread</th>\n",
       "      <th>author</th>\n",
       "      <th>published</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "      <th>crawled</th>\n",
       "      <th>site_url</th>\n",
       "      <th>country</th>\n",
       "      <th>domain_rank</th>\n",
       "      <th>thread_title</th>\n",
       "      <th>spam_score</th>\n",
       "      <th>main_img_url</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>participants_count</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>shares</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6a175f46bcd24d39b3e962ad0f29936721db70db</td>\n",
       "      <td>0</td>\n",
       "      <td>Barracuda Brigade</td>\n",
       "      <td>2016-10-26T21:41:00.000+03:00</td>\n",
       "      <td>Muslims BUSTED: They Stole Millions In Gov’t B...</td>\n",
       "      <td>Print They should pay all the back all the mon...</td>\n",
       "      <td>english</td>\n",
       "      <td>2016-10-27T01:49:27.168+03:00</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>US</td>\n",
       "      <td>25689.0</td>\n",
       "      <td>Muslims BUSTED: They Stole Millions In Gov’t B...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2bdc29d12605ef9cf3f09f9875040a7113be5d5b</td>\n",
       "      <td>0</td>\n",
       "      <td>reasoning with facts</td>\n",
       "      <td>2016-10-29T08:47:11.259+03:00</td>\n",
       "      <td>Re: Why Did Attorney General Loretta Lynch Ple...</td>\n",
       "      <td>Why Did Attorney General Loretta Lynch Plead T...</td>\n",
       "      <td>english</td>\n",
       "      <td>2016-10-29T08:47:11.259+03:00</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>US</td>\n",
       "      <td>25689.0</td>\n",
       "      <td>Re: Why Did Attorney General Loretta Lynch Ple...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c70e149fdd53de5e61c29281100b9de0ed268bc3</td>\n",
       "      <td>0</td>\n",
       "      <td>Barracuda Brigade</td>\n",
       "      <td>2016-10-31T01:41:49.479+02:00</td>\n",
       "      <td>BREAKING: Weiner Cooperating With FBI On Hilla...</td>\n",
       "      <td>Red State : \\nFox News Sunday reported this mo...</td>\n",
       "      <td>english</td>\n",
       "      <td>2016-10-31T01:41:49.479+02:00</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>US</td>\n",
       "      <td>25689.0</td>\n",
       "      <td>BREAKING: Weiner Cooperating With FBI On Hilla...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7cf7c15731ac2a116dd7f629bd57ea468ed70284</td>\n",
       "      <td>0</td>\n",
       "      <td>Fed Up</td>\n",
       "      <td>2016-11-01T05:22:00.000+02:00</td>\n",
       "      <td>PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...</td>\n",
       "      <td>Email Kayla Mueller was a prisoner and torture...</td>\n",
       "      <td>english</td>\n",
       "      <td>2016-11-01T15:46:26.304+02:00</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>US</td>\n",
       "      <td>25689.0</td>\n",
       "      <td>PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...</td>\n",
       "      <td>0.068</td>\n",
       "      <td>http://100percentfedup.com/wp-content/uploads/...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0206b54719c7e241ffe0ad4315b808290dbe6c0f</td>\n",
       "      <td>0</td>\n",
       "      <td>Fed Up</td>\n",
       "      <td>2016-11-01T21:56:00.000+02:00</td>\n",
       "      <td>FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...</td>\n",
       "      <td>Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ...</td>\n",
       "      <td>english</td>\n",
       "      <td>2016-11-01T23:59:42.266+02:00</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>US</td>\n",
       "      <td>25689.0</td>\n",
       "      <td>FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...</td>\n",
       "      <td>0.865</td>\n",
       "      <td>http://100percentfedup.com/wp-content/uploads/...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bias</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       uuid  ord_in_thread  \\\n",
       "0  6a175f46bcd24d39b3e962ad0f29936721db70db              0   \n",
       "1  2bdc29d12605ef9cf3f09f9875040a7113be5d5b              0   \n",
       "2  c70e149fdd53de5e61c29281100b9de0ed268bc3              0   \n",
       "3  7cf7c15731ac2a116dd7f629bd57ea468ed70284              0   \n",
       "4  0206b54719c7e241ffe0ad4315b808290dbe6c0f              0   \n",
       "\n",
       "                 author                      published  \\\n",
       "0     Barracuda Brigade  2016-10-26T21:41:00.000+03:00   \n",
       "1  reasoning with facts  2016-10-29T08:47:11.259+03:00   \n",
       "2     Barracuda Brigade  2016-10-31T01:41:49.479+02:00   \n",
       "3                Fed Up  2016-11-01T05:22:00.000+02:00   \n",
       "4                Fed Up  2016-11-01T21:56:00.000+02:00   \n",
       "\n",
       "                                               title  \\\n",
       "0  Muslims BUSTED: They Stole Millions In Gov’t B...   \n",
       "1  Re: Why Did Attorney General Loretta Lynch Ple...   \n",
       "2  BREAKING: Weiner Cooperating With FBI On Hilla...   \n",
       "3  PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...   \n",
       "4  FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...   \n",
       "\n",
       "                                                text language  \\\n",
       "0  Print They should pay all the back all the mon...  english   \n",
       "1  Why Did Attorney General Loretta Lynch Plead T...  english   \n",
       "2  Red State : \\nFox News Sunday reported this mo...  english   \n",
       "3  Email Kayla Mueller was a prisoner and torture...  english   \n",
       "4  Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ...  english   \n",
       "\n",
       "                         crawled             site_url country  domain_rank  \\\n",
       "0  2016-10-27T01:49:27.168+03:00  100percentfedup.com      US      25689.0   \n",
       "1  2016-10-29T08:47:11.259+03:00  100percentfedup.com      US      25689.0   \n",
       "2  2016-10-31T01:41:49.479+02:00  100percentfedup.com      US      25689.0   \n",
       "3  2016-11-01T15:46:26.304+02:00  100percentfedup.com      US      25689.0   \n",
       "4  2016-11-01T23:59:42.266+02:00  100percentfedup.com      US      25689.0   \n",
       "\n",
       "                                        thread_title  spam_score  \\\n",
       "0  Muslims BUSTED: They Stole Millions In Gov’t B...       0.000   \n",
       "1  Re: Why Did Attorney General Loretta Lynch Ple...       0.000   \n",
       "2  BREAKING: Weiner Cooperating With FBI On Hilla...       0.000   \n",
       "3  PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...       0.068   \n",
       "4  FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...       0.865   \n",
       "\n",
       "                                        main_img_url  replies_count  \\\n",
       "0  http://bb4sp.com/wp-content/uploads/2016/10/Fu...              0   \n",
       "1  http://bb4sp.com/wp-content/uploads/2016/10/Fu...              0   \n",
       "2  http://bb4sp.com/wp-content/uploads/2016/10/Fu...              0   \n",
       "3  http://100percentfedup.com/wp-content/uploads/...              0   \n",
       "4  http://100percentfedup.com/wp-content/uploads/...              0   \n",
       "\n",
       "   participants_count  likes  comments  shares  type  \n",
       "0                   1      0         0       0  bias  \n",
       "1                   1      0         0       0  bias  \n",
       "2                   1      0         0       0  bias  \n",
       "3                   0      0         0       0  bias  \n",
       "4                   0      0         0       0  bias  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = df1[(df1.language == 'english') & (df1.type == 'fake')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = df1[['text', 'type']]\n",
    "df1 = df1.rename(columns={'type': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('/data/fake_or_real_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df2[['text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2['label'] = df2['label'].map({'FAKE': 'fake', 'REAL': 'real'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2], axis = 0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 20000\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'label'], dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 98886 unique tokes. \n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokes. ' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6354, 1000)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6354, 2)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "df['label'] = df['label'].map({'fake': 1, 'real': 0})\n",
    "# print(df.label)\n",
    "labels = to_categorical(df.label, num_classes=2)\n",
    "type(labels)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (6354, 1000)\n",
      "Shape of label tensor: (6354,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', df.label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SPLIT = 0.2\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = data[:-num_validation_samples]\n",
    "y_train = labels[:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = labels[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "GLOVE_DIR = '/data'\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'),encoding = \"utf-8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing embedding matrix.\n"
     ]
    }
   ],
   "source": [
    "print('Preparing embedding matrix.')\n",
    "EMBEDDING_DIM = 100\n",
    "num_words = min(MAX_NB_WORDS, len(word_index))\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NB_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(35)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(2, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Dense(128, activation='relu')(embedded_sequences)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(2, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras import optimizers\n",
    "model = Model(sequence_input, preds)\n",
    "# sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5084 samples, validate on 1270 samples\n",
      "Epoch 1/20\n",
      "5084/5084 [==============================] - 20s - loss: 0.0185 - acc: 0.9996 - val_loss: 0.5107 - val_acc: 0.8173\n",
      "Epoch 2/20\n",
      "5084/5084 [==============================] - 20s - loss: 0.0091 - acc: 0.9996 - val_loss: 0.5478 - val_acc: 0.8228\n",
      "Epoch 3/20\n",
      "5084/5084 [==============================] - 20s - loss: 0.0058 - acc: 0.9996 - val_loss: 0.5769 - val_acc: 0.8220\n",
      "Epoch 4/20\n",
      "5084/5084 [==============================] - 20s - loss: 0.0040 - acc: 0.9996 - val_loss: 0.6209 - val_acc: 0.8205\n",
      "Epoch 5/20\n",
      "5084/5084 [==============================] - 20s - loss: 0.0027 - acc: 0.9998 - val_loss: 0.6455 - val_acc: 0.8236\n",
      "Epoch 6/20\n",
      "5084/5084 [==============================] - 20s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6912 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "5084/5084 [==============================] - 20s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.7244 - val_acc: 0.8189\n",
      "Epoch 8/20\n",
      "5084/5084 [==============================] - 20s - loss: 7.3203e-04 - acc: 1.0000 - val_loss: 0.8269 - val_acc: 0.8102\n",
      "Epoch 9/20\n",
      "5084/5084 [==============================] - 20s - loss: 1.0904 - acc: 0.8708 - val_loss: 0.4976 - val_acc: 0.8094\n",
      "Epoch 10/20\n",
      "5084/5084 [==============================] - 20s - loss: 0.0152 - acc: 1.0000 - val_loss: 0.5214 - val_acc: 0.8228\n",
      "Epoch 11/20\n",
      "5084/5084 [==============================] - 20s - loss: 0.0083 - acc: 1.0000 - val_loss: 0.5474 - val_acc: 0.8244\n",
      "Epoch 12/20\n",
      "5084/5084 [==============================] - 20s - loss: 0.0052 - acc: 1.0000 - val_loss: 0.5864 - val_acc: 0.8244\n",
      "Epoch 13/20\n",
      "5084/5084 [==============================] - 20s - loss: 0.0036 - acc: 1.0000 - val_loss: 0.6245 - val_acc: 0.8205\n",
      "Epoch 14/20\n",
      "5084/5084 [==============================] - 20s - loss: 0.0025 - acc: 1.0000 - val_loss: 0.6599 - val_acc: 0.8244\n",
      "Epoch 15/20\n",
      "5084/5084 [==============================] - 20s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.7099 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "5084/5084 [==============================] - 20s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.7415 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "5084/5084 [==============================] - 20s - loss: 8.2915e-04 - acc: 1.0000 - val_loss: 0.7799 - val_acc: 0.8213\n",
      "Epoch 18/20\n",
      "5084/5084 [==============================] - 20s - loss: 5.7173e-04 - acc: 1.0000 - val_loss: 0.8391 - val_acc: 0.8157\n",
      "Epoch 19/20\n",
      "5084/5084 [==============================] - 20s - loss: 3.5596e-04 - acc: 1.0000 - val_loss: 0.9336 - val_acc: 0.8063\n",
      "Epoch 20/20\n",
      "5084/5084 [==============================] - 20s - loss: 2.4207e-04 - acc: 1.0000 - val_loss: 0.9177 - val_acc: 0.8134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2d9ae7e2b0>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=800,\n",
    "          epochs=20,\n",
    "          validation_data=(x_val, y_val)\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 1000, 100)         2000000   \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1000, 128)         12928     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1000, 128)         16512     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1000, 128)         16512     \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 128)               16384128  \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 18,430,338\n",
      "Trainable params: 16,430,338\n",
      "Non-trainable params: 2,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[286, 338],\n",
       "       [323, 323]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_prob = model.predict(x_val)\n",
    "y_pred = np.argmax(y_prob,axis=-1)\n",
    "confusion_matrix(df.label[-num_validation_samples:], y_pred)\n",
    "# df.label[-num_validation_samples:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/src/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'Dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-180-18020722eab8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvis_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mSVG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dot'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/src/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rankdir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# pydot raises a generic Exception here,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# so no specific class can be caught.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[1;32m     28\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
